{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BERVyJe5Huqg",
        "outputId": "64eb229f-2bab-46d6-87e5-549c48564516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import modules\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "plt.style.use('seaborn-poster')\n",
        "from scipy.special import gamma\n",
        "import pandas as pd\n",
        "\n",
        "device =  'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "dtype = torch.float64\n",
        "#device = 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JDRLxFjiNl83"
      },
      "outputs": [],
      "source": [
        "def generate_data(size=100000, low=-0.5, high=0.5, type_n=3, prop=0.5, custom_data=None, n_each=None):\n",
        "    if custom_data is not None:\n",
        "      size = len(custom_data)   \n",
        "    #output vector\n",
        "    c1, c2 = [], []\n",
        "    #define the radius and length\n",
        "    ll = high - low\n",
        "    center = np.repeat((low+high)/2, type_n)\n",
        "    n_volume = ll**type_n\n",
        "    \n",
        "    #checking whether the proportion is valid\n",
        "    r_max = high - center[0]\n",
        "    prop_max = (1/n_volume)*(r_max**type_n*(np.pi**(0.5*type_n)))*(1/gamma(type_n*0.5+1))\n",
        "    \n",
        "    #radius\n",
        "    prop_volume = prop*n_volume\n",
        "    radius_sq = ((prop_volume*gamma((type_n/2)+1))/(np.pi**(type_n*0.5)))**(2/type_n)\n",
        "       \n",
        "    for j in range(size):\n",
        "        #generate from uniform distribution\n",
        "        if custom_data is None:\n",
        "          tmp = np.random.uniform(low=low, high=high, size=type_n)\n",
        "        else:\n",
        "          tmp = custom_data[j]\n",
        "        tmp_sum = np.sum((tmp-center)**2)\n",
        "\n",
        "        if tmp_sum <= radius_sq:\n",
        "            c2.append(tmp)\n",
        "        else:\n",
        "            c1.append(tmp)  \n",
        "\n",
        "    #type conversion\n",
        "    cube, sphere = np.array(c1), np.array(c2)\n",
        "\n",
        "    if n_each is not None:\n",
        "      cube = cube[:n_each]\n",
        "      sphere = sphere[:n_each]\n",
        "    \n",
        "    features = np.concatenate((cube, sphere), axis=0)\n",
        "    target = np.concatenate((np.zeros(len(cube)), np.ones(len(sphere))))\n",
        "    target = pd.get_dummies(target).values\n",
        "\n",
        "    return cube, sphere, features, target, np.round(prop_max, 4), len(sphere)/size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M3Z2G_TIFJe"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWMnq1_0IHXP",
        "outputId": "21b504f5-2713-4426-b330-e1665751c185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0.000727,  0.405   ,  0.302   ],\n",
              "        [ 0.487   ,  0.354   ,  0.313   ],\n",
              "        [-0.469   , -0.29    ,  0.475   ],\n",
              "        ...,\n",
              "        [-0.31    ,  0.073   , -0.117   ],\n",
              "        [-0.117   , -0.42    ,  0.0665  ],\n",
              "        [ 0.328   ,  0.197   ,  0.00437 ]]),\n",
              " array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = pd.read_csv('y_train.csv')\n",
        "x_train = pd.read_csv('x_train.csv')\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZHmeAJrKw11"
      },
      "source": [
        "### `Utility Functions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iDoTHoIpK5FQ"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  x = torch.tensor(x, device=device, dtype=dtype)\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def mse(target, predicted):\n",
        "  res = target[:,0] != predicted[:,0]\n",
        "  return np.mean(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWR5IGrNKfQ7"
      },
      "source": [
        "### Comparing Algorithms\n",
        "\n",
        "- Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cKJPbmmKqzE",
        "outputId": "17910dda-0ef0-4249-c4cd-d8f7a2e40798"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ab30a\\AppData\\Local\\Temp/ipykernel_10904/2288919135.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features)\n",
            "C:\\Users\\ab30a\\AppData\\Local\\Temp/ipykernel_10904/3085974255.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, device=device, dtype=dtype)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       ...,\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1]], dtype=uint8)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class backPropagation():\n",
        "\n",
        "  def __init__(self, dimension=None, activation_fun = None, device=device, niter=100000, dtype=torch.float64):\n",
        "    self.dimension = dimension\n",
        "    self.activation_fun = activation_fun\n",
        "    self.device = device\n",
        "    self.niter = niter\n",
        "    self.dtype=dtype\n",
        "\n",
        "    #initialize weights\n",
        "    input_size = self.dimension[0]\n",
        "    hidden_size = self.dimension[1]\n",
        "    output_size = self.dimension[2]\n",
        "    \n",
        "    #initializing weight for the hidden layer\n",
        "    self.W1 = torch.randn((input_size, hidden_size), device=self.device, dtype=dtype)\n",
        "    # initializing weight for the output layer\n",
        "    self.W2 = torch.randn((hidden_size , output_size), device=self.device, dtype=dtype)\n",
        " \n",
        "    #bias parameter\n",
        "    bias_W1 = torch.randn((1, hidden_size), device=self.device, dtype=dtype)\n",
        "    bias_W2 = torch.randn((1, output_size), device=self.device, dtype=dtype)\n",
        "\n",
        "    #weight with bias\n",
        "    self.W1_constant = torch.concat((self.W1, bias_W1), axis=0)\n",
        "    self.W2_constant = torch.concat((self.W2, bias_W2), axis=0)\n",
        "\n",
        "  def fit(self, xtrain=None, ytrain=None, learning_rate=0.1):\n",
        "    N, p = xtrain.shape\n",
        "    xtrain = torch.tensor(xtrain, device=self.device)\n",
        "    #xtrain = torch.from_numpy(xtrain).type(self.dtype).to(self.device)\n",
        "    ytrain = torch.tensor(y_train, device=device)\n",
        "    bias = torch.ones((N,1), device=self.device)\n",
        "    features = torch.concat((xtrain, bias), axis=1)\n",
        "    features = torch.tensor(features)\n",
        "\n",
        "    for itr in range(self.niter):\n",
        "      Z1 = features @ self.W1_constant\n",
        "      A1 = self.activation_fun(Z1)\n",
        "      A1_bias = torch.concat((A1, bias), axis=1)\n",
        "      #output layer\n",
        "      Z2 = A1_bias @ self.W2_constant\n",
        "      A2 = self.activation_fun(Z2)\n",
        "      E1 = A2 - ytrain\n",
        "      # backpropagation\n",
        "      E1 = A2 - ytrain\n",
        "      #err_norm.append(E1)\n",
        "      dW1 = E1 * A2 * (1 - A2)\n",
        "      E2 = dW1 @ self.W2.T\n",
        "      dW2 = E2 * A1 * (1 - A1)\n",
        "      #update weight\n",
        "      W2_update = A1_bias.T @ dW1\n",
        "      W1_update = features.T @ dW2\n",
        "      self.W2_constant = self.W2_constant - (learning_rate * W2_update)\n",
        "      self.W1_constant = self.W1_constant - (learning_rate * W1_update)\n",
        "      self.W2 = self.W2_constant[:-1, :]\n",
        "\n",
        "  def predict(self, xtest):\n",
        "    xtest = torch.tensor(xtest, device=self.device, dtype=self.dtype)\n",
        "    const = torch.ones((len(xtest),1), dtype=dtype, device=device)\n",
        "    features_bias= torch.concat((xtest, const), axis=1)\n",
        "    Z = sigmoid(features_bias @ self.W1_constant)\n",
        "    Z = torch.concat((Z, const), axis=1)\n",
        "    out = sigmoid(Z @ self.W2_constant)\n",
        "    output = out.cpu().numpy()\n",
        "    predicted = pd.get_dummies(np.argmax(output, axis=1)).values\n",
        "    #return\n",
        "    return predicted\n",
        "\n",
        "     \n",
        "model = backPropagation([3,6,2], device=device, activation_fun=sigmoid)\n",
        "model.fit(x_train, y_train)\n",
        "ypred = model.predict(x_train)\n",
        "ypred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWfVqgpjMP6a",
        "outputId": "f2f79a45-ccaf-48cf-b9c9-456a686ae5e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.052"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse(ypred, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm_ihTV6NNsE"
      },
      "source": [
        "### `Test Data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifgYDnXXNSli",
        "outputId": "7195c087-acc3-4599-9825-48c2dc948c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-5.0000000e-01, -5.0000000e-01, -5.0000000e-01],\n",
              "        [-5.0000000e-01, -5.0000000e-01, -4.8000000e-01],\n",
              "        [-5.0000000e-01, -5.0000000e-01, -4.6000000e-01],\n",
              "        ...,\n",
              "        [ 4.8000000e-01,  1.0000000e-01,  4.4408921e-16],\n",
              "        [ 4.8000000e-01,  1.0000000e-01,  2.0000000e-02],\n",
              "        [ 4.8000000e-01,  1.0000000e-01,  4.0000000e-02]]),\n",
              " array([[1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        ...,\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1]], dtype=uint8))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h = 0.02\n",
        "#h = 0.1\n",
        "dataStep = np.arange(-0.5, 0.5001, h)\n",
        "dataGrid = np.array([[i,j,k] for i in dataStep for j in dataStep for k in dataStep])\n",
        "df = generate_data(custom_data=dataGrid)\n",
        "xtest = df[2]\n",
        "ytest = df[3]\n",
        "xtest, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KdFJ5-pINu_L"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((132651, 3), (132651, 2))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtest.shape, ytest.shape\n",
        "#np.savetxt('x_test.csv', xtest, delimiter=',')\n",
        "#np.savetxt('y_test.csv', ytest, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsMdLblgOFon",
        "outputId": "e728942c-e580-47fa-91f5-d6199855fa1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ab30a\\AppData\\Local\\Temp/ipykernel_10904/3085974255.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, device=device, dtype=dtype)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.07828060097549208"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ypred_test = model.predict(xtest)\n",
        "mse(ytest, ypred_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT5ket6Zw1Dp"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6_I6e_Iw4TW",
        "outputId": "a7fc9337-66c3-4461-beaa-59bfd17a45c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[59711,  2958],\n",
              "       [ 7426, 62556]], dtype=int64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(ytest[:,0], ypred_test[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62669"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(ytest[:,0] == 0 & ypred_test[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhDEWQazONM5"
      },
      "source": [
        "### `K-Nearest Neighbors`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UyQAF61uOMP8"
      },
      "outputs": [],
      "source": [
        "def euclideanDistance(x,y):\n",
        "  tmp = x-y\n",
        "  return np.sqrt(np.dot(tmp, tmp))\n",
        "\n",
        "def absDistance(x, y):\n",
        "  return np.sum(x-y)\n",
        "\n",
        "class kNN():\n",
        "\n",
        "  def __init__(self, k, distFunc=None):\n",
        "    self.k = k\n",
        "    self.distanceFunction = distFunc\n",
        "\n",
        "  def _fitPredict(self, xrow):\n",
        "    xtrain = self.xtrain\n",
        "    ytrain = self.ytrain\n",
        "    dist = np.apply_along_axis(euclideanDistance, 1, xtrain, xrow)\n",
        "    dist_ind = sorted(range(len(dist)), key = lambda sub: dist[sub])[:self.k]\n",
        "    number_list = ytrain[dist_ind]\n",
        "    (unique, counts) = np.unique(number_list, return_counts=True)\n",
        "    prop = counts/self.k\n",
        "    kSmall = min(prop)\n",
        "    ind = list(prop).index(kSmall)\n",
        "    return unique[ind]\n",
        "\n",
        "  def fitPredict(self, xtrain=None, ytrain=None, xtest=None):\n",
        "    self.xtrain = xtrain\n",
        "    self.ytrain = ytrain\n",
        "\n",
        "    if xtest is None:\n",
        "      xtest = xtrain\n",
        "    else:\n",
        "      xtest = xtest\n",
        "    ypred = np.apply_along_axis(self._fitPredict, 1, xtest)\n",
        "    return ypred\n",
        "\n",
        "  def mse(self, yhat, y):\n",
        "    return np.mean(yhat != y)\n",
        "\n",
        "  def accuracy(self, yhat, y):\n",
        "    return 1 - self.mse(yhat, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stI2eSwqOnws"
      },
      "source": [
        "#### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ghP_8chlPNS9",
        "outputId": "dcf8e558-30f0-4524-eb19-843c9fc1f5ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' model = kNN(1, absDistance)\\ny_train_mod = y_train[:,0]\\ny_test = ytest[:,0]\\nyhat = model.fitPredict(x_train, y_train_mod, x_train)\\nmodel.mse(yhat, y_train_mod) '"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' model = kNN(1, absDistance)\n",
        "y_train_mod = y_train[:,0]\n",
        "y_test = ytest[:,0]\n",
        "yhat = model.fitPredict(x_train, y_train_mod, x_train)\n",
        "model.mse(yhat, y_train_mod) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYUP-94YOq9P",
        "outputId": "575ed2ef-668b-4d85-a5b5-e74a6b62952c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.045"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = kNN(2, euclideanDistance)\n",
        "y_train_mod = y_train[:,0]\n",
        "y_test = ytest[:,0]\n",
        "yhat = model.fitPredict(x_train, y_train_mod, x_train)\n",
        "model.mse(yhat, y_train_mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZiF_LDqPgkn"
      },
      "source": [
        "#### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLlLW2R9Prdf",
        "outputId": "a6a8a1ad-df69-4eeb-a334-ca9459751a27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09869507203111925"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = kNN(2, euclideanDistance)\n",
        "yhat = model.fitPredict(x_train, y_train_mod, xtest)\n",
        "model.mse(yhat, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7KqI0DIxf2x",
        "outputId": "1933a355-3cfb-4f98-8696-3deece8d2d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[60684, 11107],\n",
              "       [ 1985, 58875]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(yhat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEZURzg1l7mq"
      },
      "source": [
        "#### Prediction for `N=4`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSYA9EGJm7Ap",
        "outputId": "4b2d3ee3-25eb-424f-9c64-3df10b445901"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.285 , -0.357 , -0.0548, -0.437 ],\n",
              "        [-0.116 , -0.2   , -0.139 , -0.431 ],\n",
              "        [ 0.273 ,  0.27  , -0.33  , -0.277 ],\n",
              "        ...,\n",
              "        [-0.24  ,  0.0626, -0.332 ,  0.103 ],\n",
              "        [ 0.0128, -0.0954, -0.428 ,  0.205 ],\n",
              "        [ 0.103 ,  0.0829,  0.388 ,  0.191 ]]),\n",
              " array([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train1 = pd.read_csv('y_train4.csv')\n",
        "x_train1 = pd.read_csv('x_train4.csv')\n",
        "x_train1, y_train1 = np.array(x_train1), np.array(y_train1)\n",
        "x_train1, y_train1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPRjfXojl_0H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjBhEOEgnjya"
      },
      "source": [
        "#### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQpW0Jcnllu",
        "outputId": "aa2b6083-3112-4154-bb6e-4b06efec47f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.5  , -0.5  , -0.5  , -0.5  ],\n",
              "        [-0.5  , -0.5  , -0.5  , -0.445],\n",
              "        [-0.5  , -0.5  , -0.5  , -0.39 ],\n",
              "        ...,\n",
              "        [ 0.49 ,  0.27 , -0.005,  0.05 ],\n",
              "        [ 0.49 ,  0.27 ,  0.05 , -0.005],\n",
              "        [ 0.49 ,  0.27 ,  0.05 ,  0.05 ]]),\n",
              " (130321, 2))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h = 0.055\n",
        "#h = 0.1\n",
        "dataStep = np.arange(-0.5, 0.5001, h)\n",
        "dataGrid1 = np.array([[i,j,k, w] for i in dataStep for j in dataStep for k in dataStep for w in dataStep])\n",
        "df1 = generate_data(custom_data=dataGrid1, type_n=4)\n",
        "xtest1 = df1[2]\n",
        "ytest1 = df1[3]\n",
        "xtest1, ytest1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gVsuLrEIqlO0"
      },
      "outputs": [],
      "source": [
        "#np.savetxt('x_test1.csv', xtest1, delimiter=',')\n",
        "#np.savetxt('y_test1.csv', ytest1, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imODQkrnrKI6"
      },
      "source": [
        "#### Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msDt7tVCrM47",
        "outputId": "8d390fc6-2444-4e40-bfc1-62219ee116eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ab30a\\AppData\\Local\\Temp/ipykernel_10904/2288919135.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features = torch.tensor(features)\n",
            "C:\\Users\\ab30a\\AppData\\Local\\Temp/ipykernel_10904/3085974255.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, device=device, dtype=dtype)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = backPropagation([4,15,2], device=device, activation_fun=sigmoid, niter=200000)\n",
        "model1.fit(x_train1, y_train1)\n",
        "ypred1 = model1.predict(xtest1)\n",
        "ypred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGIkLLOvsnGO",
        "outputId": "c622e526-8f39-4d91-d3cd-245ca562f345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.10785675370815141"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse(ypred1, ytest1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHwJaglwx2c7",
        "outputId": "0113c134-fd95-487a-bbdf-b341711cd32a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[41588,  1365],\n",
              "       [12691, 74677]], dtype=int64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(ypred1[:,0], ytest1[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH49qQ4NuACn"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXNbT9MTuBp-",
        "outputId": "00ce6966-963e-4263-8f95-1fd3746b253f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.076"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = kNN(2, euclideanDistance)\n",
        "y_train_mod1 = y_train1[:,0]\n",
        "y_test1 = ytest1[:,0]\n",
        "yhat = model.fitPredict(x_train1, y_train_mod1, x_train1)\n",
        "model.mse(yhat, y_train_mod1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3BIAwRrevLVM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.12682530060389346"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = kNN(2, euclideanDistance)\n",
        "y_train_mod1 = y_train1[:,0]\n",
        "y_test1 = ytest1[:,0]\n",
        "yhat = model.fitPredict(x_train1, y_train_mod1, xtest1)\n",
        "model.mse(yhat, y_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QC12vpGdx6nb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[47794, 10043],\n",
              "       [ 6485, 65999]], dtype=int64)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(yhat, y_test1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SubmitFinalProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
